# æ•°æ®å¤„ç†é—®é¢˜

æ•°æ®é‡‡é›†ã€è§£æå’Œå­˜å‚¨ä¸­çš„å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆã€‚

---

## ç¼–ç é”™è¯¯

### UnicodeDecodeError

**é—®é¢˜è¡¨ç°**:

```python
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0
```

**åŸå› **: æ–‡ä»¶æˆ–æ•°æ®ä½¿ç”¨äº†ä¸åŒçš„ç¼–ç æ ¼å¼

**è§£å†³æ–¹æ¡ˆ**:

#### 1. è‡ªåŠ¨æ£€æµ‹ç¼–ç 

```python
import chardet

# æ£€æµ‹æ–‡ä»¶ç¼–ç 
with open('file.txt', 'rb') as f:
    raw_data = f.read()
    result = chardet.detect(raw_data)
    encoding = result['encoding']
    confidence = result['confidence']

print(f"Encoding: {encoding} (Confidence: {confidence})")

# ä½¿ç”¨æ£€æµ‹åˆ°çš„ç¼–ç è¯»å–
with open('file.txt', 'r', encoding=encoding) as f:
    content = f.read()
```

#### 2. å¤„ç†ç½‘é¡µç¼–ç 

```python
import requests
from chardet import detect

response = requests.get(url)

# æ–¹æ³• 1: è®© requests è‡ªåŠ¨æ£€æµ‹
response.encoding = response.apparent_encoding
text = response.text

# æ–¹æ³• 2: æ‰‹åŠ¨æ£€æµ‹
encoding = detect(response.content)['encoding']
text = response.content.decode(encoding, errors='ignore')

# æ–¹æ³• 3: å°è¯•å¸¸è§ç¼–ç 
encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030', 'big5']
for enc in encodings:
    try:
        text = response.content.decode(enc)
        break
    except UnicodeDecodeError:
        continue
```

#### 3. å¿½ç•¥é”™è¯¯å­—ç¬¦

```python
# å¿½ç•¥æ— æ³•è§£ç çš„å­—ç¬¦
text = data.decode('utf-8', errors='ignore')

# æˆ–æ›¿æ¢ä¸º ?
text = data.decode('utf-8', errors='replace')

# æˆ–ä½¿ç”¨æ›¿ä»£æ–¹æ¡ˆ
text = data.decode('utf-8', errors='backslashreplace')
```

### UnicodeEncodeError

**é—®é¢˜è¡¨ç°**:

```python
UnicodeEncodeError: 'ascii' codec can't encode character '\u4e2d'
```

**è§£å†³æ–¹æ¡ˆ**:

```python
# å†™å…¥æ–‡ä»¶æ—¶æŒ‡å®šç¼–ç 
with open('output.txt', 'w', encoding='utf-8') as f:
    f.write(chinese_text)

# æ‰“å°åˆ°æ§åˆ¶å° (Windows)
import sys
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# JSON è¾“å‡ºä¿ç•™ä¸­æ–‡
import json
json.dumps(data, ensure_ascii=False, indent=2)
```

---

## JSON è§£æå¤±è´¥

### JSONDecodeError

**é—®é¢˜è¡¨ç°**:

```python
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
```

**åŸå› åˆ†æ**:

1. å“åº”ä¸æ˜¯ JSON æ ¼å¼
2. JSON æ ¼å¼é”™è¯¯
3. ç©ºå“åº”
4. HTML é”™è¯¯é¡µé¢

**è§£å†³æ–¹æ¡ˆ**:

#### 1. æ£€æŸ¥å“åº”å†…å®¹

```python
import requests
import json

response = requests.get(url)

# å…ˆæ£€æŸ¥çŠ¶æ€ç 
if response.status_code != 200:
    print(f"Error: {response.status_code}")
    print(response.text)
    exit()

# æ£€æŸ¥ Content-Type
content_type = response.headers.get('Content-Type', '')
if 'application/json' not in content_type:
    print(f"Warning: Content-Type is {content_type}")

# å®‰å…¨è§£æ
try:
    data = response.json()
except json.JSONDecodeError as e:
    print(f"JSON Parse Error: {e}")
    print(f"Response text: {response.text[:500]}")  # æ‰“å°å‰500å­—ç¬¦
    data = None
```

#### 2. å¤„ç†ç•¸å½¢ JSON

```python
import json5  # pip install json5

# json5 å¯ä»¥è§£æå¸¦æ³¨é‡Šã€å°¾éšé€—å·çš„ JSON
text = '''
{
    "name": "value",  // æ³¨é‡Š
    "items": [1, 2, 3,],  // å°¾éšé€—å·
}
'''

data = json5.loads(text)
```

#### 3. ä¿®å¤å¸¸è§ JSON é—®é¢˜

```python
import re
import json

def fix_json(text):
    """ä¿®å¤å¸¸è§çš„ JSON é—®é¢˜"""
    # ç§»é™¤ JavaScript æ³¨é‡Š
    text = re.sub(r'//.*?\n', '\n', text)
    text = re.sub(r'/\*.*?\*/', '', text, flags=re.DOTALL)

    # ç§»é™¤å°¾éšé€—å·
    text = re.sub(r',\s*}', '}', text)
    text = re.sub(r',\s*]', ']', text)

    # å•å¼•å·è½¬åŒå¼•å· (è°¨æ…ä½¿ç”¨)
    # text = text.replace("'", '"')

    return text

# ä½¿ç”¨
text = response.text
fixed_text = fix_json(text)
data = json.loads(fixed_text)
```

#### 4. ä» HTML ä¸­æå– JSON

```python
import re
import json
from bs4 import BeautifulSoup

html = response.text

# æ–¹æ³• 1: ä» script æ ‡ç­¾æå–
soup = BeautifulSoup(html, 'lxml')
script = soup.find('script', {'id': 'initial-data'})
if script:
    data = json.loads(script.string)

# æ–¹æ³• 2: ä½¿ç”¨æ­£åˆ™æå–
match = re.search(r'var\s+data\s*=\s*({.*?});', html, re.DOTALL)
if match:
    json_str = match.group(1)
    data = json.loads(json_str)

# æ–¹æ³• 3: æå– JSON-LD
script = soup.find('script', {'type': 'application/ld+json'})
if script:
    data = json.loads(script.string)
```

---

## æ•°æ®åº“è¿æ¥é—®é¢˜

### MongoDB è¿æ¥å¤±è´¥

**é—®é¢˜è¡¨ç°**:

```python
ServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused
```

**è§£å†³æ–¹æ¡ˆ**:

```python
import pymongo
from pymongo.errors import ServerSelectionTimeoutError

# æ·»åŠ è¶…æ—¶å’Œé”™è¯¯å¤„ç†
try:
    client = pymongo.MongoClient(
        'mongodb://localhost:27017/',
        serverSelectionTimeoutMS=5000,
        connectTimeoutMS=5000,
        socketTimeoutMS=5000
    )

    # æµ‹è¯•è¿æ¥
    client.server_info()
    print("âœ… MongoDB connected")

except ServerSelectionTimeoutError as e:
    print(f"âŒ MongoDB connection failed: {e}")
    print("æç¤º:")
    print("1. æ£€æŸ¥ MongoDB æ˜¯å¦è¿è¡Œ: systemctl status mongod")
    print("2. æ£€æŸ¥ç«¯å£: netstat -an | grep 27017")
    print("3. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®")
    exit()
```

#### è®¤è¯é—®é¢˜

```python
# å¸¦è®¤è¯çš„è¿æ¥
client = pymongo.MongoClient(
    'mongodb://username:password@localhost:27017/',
    authSource='admin',  # è®¤è¯æ•°æ®åº“
    authMechanism='SCRAM-SHA-256'  # è®¤è¯æœºåˆ¶
)

# æˆ–ä½¿ç”¨ URI æ ¼å¼
uri = 'mongodb://username:password@host1:27017,host2:27017/database?authSource=admin'
client = pymongo.MongoClient(uri)
```

### MySQL è¿æ¥é—®é¢˜

**é—®é¢˜è¡¨ç°**:

```python
Error 2003: Can't connect to MySQL server on 'localhost'
```

**è§£å†³æ–¹æ¡ˆ**:

```python
import mysql.connector
from mysql.connector import Error

try:
    connection = mysql.connector.connect(
        host='localhost',
        port=3306,
        database='testdb',
        user='root',
        password='password',
        connect_timeout=10,
        autocommit=True,
        charset='utf8mb4'
    )

    if connection.is_connected():
        db_info = connection.get_server_info()
        print(f"âœ… Connected to MySQL Server version {db_info}")

except Error as e:
    print(f"âŒ Error: {e}")
    print("æ£€æŸ¥é¡¹:")
    print("1. MySQL æœåŠ¡æ˜¯å¦è¿è¡Œ")
    print("2. ç”¨æˆ·åå¯†ç æ˜¯å¦æ­£ç¡®")
    print("3. æ˜¯å¦å…è®¸è¿œç¨‹è¿æ¥")
    print("4. é˜²ç«å¢™è®¾ç½®")

finally:
    if connection and connection.is_connected():
        connection.close()
```

### Redis è¿æ¥é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**:

```python
import redis
from redis.exceptions import ConnectionError

try:
    r = redis.Redis(
        host='localhost',
        port=6379,
        password='password',  # å¦‚æœæœ‰å¯†ç 
        db=0,
        decode_responses=True,
        socket_connect_timeout=5,
        socket_timeout=5
    )

    # æµ‹è¯•è¿æ¥
    r.ping()
    print("âœ… Redis connected")

except ConnectionError as e:
    print(f"âŒ Redis connection failed: {e}")
except redis.AuthenticationError:
    print("âŒ Redis authentication failed")
```

---

## æ–‡ä»¶è¯»å†™é”™è¯¯

### æ–‡ä»¶ä¸å­˜åœ¨

**é—®é¢˜è¡¨ç°**:

```python
FileNotFoundError: [Errno 2] No such file or directory: 'data.txt'
```

**è§£å†³æ–¹æ¡ˆ**:

```python
import os
from pathlib import Path

# æ–¹æ³• 1: æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
file_path = 'data.txt'
if os.path.exists(file_path):
    with open(file_path, 'r') as f:
        content = f.read()
else:
    print(f"File not found: {file_path}")

# æ–¹æ³• 2: ä½¿ç”¨ Path å¯¹è±¡
file_path = Path('data.txt')
if file_path.exists():
    content = file_path.read_text(encoding='utf-8')

# æ–¹æ³• 3: åˆ›å»ºç›®å½•
output_dir = Path('output/data')
output_dir.mkdir(parents=True, exist_ok=True)

# æ–¹æ³• 4: ä½¿ç”¨ç»å¯¹è·¯å¾„
from pathlib import Path
base_dir = Path(__file__).resolve().parent
file_path = base_dir / 'data' / 'file.txt'
```

### æƒé™é”™è¯¯

**é—®é¢˜è¡¨ç°**:

```python
PermissionError: [Errno 13] Permission denied: '/var/log/app.log'
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# Linux/Mac
# 1. ä¿®æ”¹æ–‡ä»¶æƒé™
chmod 666 /var/log/app.log

# 2. ä¿®æ”¹ç›®å½•æƒé™
chmod 777 /var/log/

# 3. ä¿®æ”¹æ‰€æœ‰è€…
sudo chown $USER:$USER /var/log/app.log

# 4. ä½¿ç”¨ç”¨æˆ·ç›®å½•
# åœ¨ä»£ç ä¸­ä½¿ç”¨ ~/data/ è€Œä¸æ˜¯ /var/log/
```

```python
# ä½¿ç”¨ç”¨æˆ·ç›®å½•
from pathlib import Path

home = Path.home()
log_dir = home / '.myapp' / 'logs'
log_dir.mkdir(parents=True, exist_ok=True)

log_file = log_dir / 'app.log'
```

---

## å†…å­˜é—®é¢˜

### å†…å­˜æº¢å‡º

**é—®é¢˜è¡¨ç°**:

```python
MemoryError
```

**è§£å†³æ–¹æ¡ˆ**:

#### 1. åˆ†æ‰¹å¤„ç†å¤§æ–‡ä»¶

```python
# ä¸è¦ä¸€æ¬¡æ€§è¯»å–æ•´ä¸ªæ–‡ä»¶
# âŒ é”™è¯¯æ–¹å¼
with open('huge_file.txt', 'r') as f:
    content = f.read()  # å¯èƒ½å¯¼è‡´å†…å­˜æº¢å‡º

# âœ… æ­£ç¡®æ–¹å¼:æŒ‰è¡Œè¯»å–
with open('huge_file.txt', 'r') as f:
    for line in f:
        process_line(line)

# æˆ–ä½¿ç”¨ç”Ÿæˆå™¨
def read_large_file(file_path, chunk_size=1024*1024):
    """åˆ†å—è¯»å–å¤§æ–‡ä»¶"""
    with open(file_path, 'r') as f:
        while True:
            chunk = f.read(chunk_size)
            if not chunk:
                break
            yield chunk

for chunk in read_large_file('huge_file.txt'):
    process_chunk(chunk)
```

#### 2. ä½¿ç”¨è¿­ä»£å™¨

```python
# âŒ ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®
urls = [f"https://example.com/page/{i}" for i in range(100000)]

# âœ… ä½¿ç”¨ç”Ÿæˆå™¨
def url_generator(count):
    for i in range(count):
        yield f"https://example.com/page/{i}"

for url in url_generator(100000):
    process_url(url)
```

#### 3. æ¸…ç†ä¸ç”¨çš„å¯¹è±¡

```python
import gc

# æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶
gc.collect()

# åˆ é™¤å¤§å¯¹è±¡
del large_dataframe
gc.collect()
```

#### 4. ä½¿ç”¨æ•°æ®åº“è€Œéå†…å­˜

```python
# âŒ æ‰€æœ‰æ•°æ®å­˜åœ¨å†…å­˜ä¸­
all_data = []
for item in items:
    all_data.append(process(item))

# âœ… ç›´æ¥å­˜å…¥æ•°æ®åº“
import sqlite3

conn = sqlite3.connect('data.db')
cursor = conn.cursor()

for item in items:
    data = process(item)
    cursor.execute("INSERT INTO results VALUES (?, ?)", (data.id, data.value))
    conn.commit()
```

---

## CSV å¤„ç†é—®é¢˜

### ç¼–ç å’Œåˆ†éš”ç¬¦

```python
import csv
import chardet

# æ£€æµ‹ç¼–ç 
with open('data.csv', 'rb') as f:
    result = chardet.detect(f.read())
    encoding = result['encoding']

# è¯»å– CSV
with open('data.csv', 'r', encoding=encoding) as f:
    # è‡ªåŠ¨æ£€æµ‹åˆ†éš”ç¬¦
    sample = f.read(1024)
    f.seek(0)
    sniffer = csv.Sniffer()
    delimiter = sniffer.sniff(sample).delimiter

    reader = csv.DictReader(f, delimiter=delimiter)
    for row in reader:
        print(row)
```

### å¤„ç†å¤§å‹ CSV

```python
import pandas as pd

# åˆ†å—è¯»å–
chunk_size = 10000
for chunk in pd.read_csv('large.csv', chunksize=chunk_size):
    process_chunk(chunk)

# åªè¯»å–éœ€è¦çš„åˆ—
df = pd.read_csv('data.csv', usecols=['col1', 'col2'])

# æŒ‡å®šæ•°æ®ç±»å‹èŠ‚çœå†…å­˜
df = pd.read_csv('data.csv', dtype={'id': 'int32', 'value': 'float32'})
```

---

## XML/HTML è§£æé—®é¢˜

### è§£æå¤±è´¥

```python
from bs4 import BeautifulSoup
from lxml import etree

html = response.text

# æ–¹æ³• 1: BeautifulSoup (å®½å®¹)
soup = BeautifulSoup(html, 'lxml')  # æˆ– 'html.parser'

# æ–¹æ³• 2: lxml (ä¸¥æ ¼)
try:
    tree = etree.HTML(html)
except etree.XMLSyntaxError as e:
    print(f"Parse error: {e}")

# å¤„ç†ç•¸å½¢ HTML
from lxml.html import fromstring
from lxml.html.clean import Cleaner

cleaner = Cleaner()
cleaned_html = cleaner.clean_html(html)
doc = fromstring(cleaned_html)
```

---

## æ•°æ®éªŒè¯

### ä½¿ç”¨ Pydantic

```python
from pydantic import BaseModel, validator, ValidationError
from typing import Optional

class Item(BaseModel):
    id: int
    name: str
    price: float
    stock: Optional[int] = 0

    @validator('price')
    def price_must_be_positive(cls, v):
        if v <= 0:
            raise ValueError('Price must be positive')
        return v

# éªŒè¯æ•°æ®
try:
    item = Item(id=1, name='Product', price=19.99)
except ValidationError as e:
    print(e.json())
```

---

## ğŸ“š ç›¸å…³ç« èŠ‚

- [æ•°æ®å­˜å‚¨æ–¹æ¡ˆ](../06-Engineering/data_storage_solutions.md)
- [Python ç¼–ç é—®é¢˜](../01-Foundations/javascript_basics.md)
- [å¸¸ç”¨å‘½ä»¤](../08-Cheat-Sheets/common_commands.md)
