#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Docs to PDF Converter - Final Edition
æœ€ç»ˆå®Œå–„ç‰ˆï¼šå¹¶è¡Œå¤„ç† + å®Œå–„ä¸­æ–‡æ”¯æŒ + PDFå†…é“¾æ¥ + æ ¼å¼ä¿®å¤

ç‰¹æ€§ï¼š
1. âš¡ å¹¶è¡Œå¤„ç† - 2-4å€é€Ÿåº¦æå‡
2. ğŸ”¤ å®Œå–„ä¸­æ–‡å­—ä½“æ”¯æŒ - æ— ç¼–ç é”™ä¹±
3. ğŸ”— å†…éƒ¨é“¾æ¥è½¬æ¢ - MDé“¾æ¥â†’PDFè·³è½¬
4. ğŸ”§ æ ¼å¼è‡ªåŠ¨ä¿®å¤ - ä»£ç å—ã€åˆ—è¡¨ã€æ ‡é¢˜
5. ğŸ’¾ æ™ºèƒ½ç¼“å­˜ - 10-20å€äºŒæ¬¡ç”Ÿæˆæé€Ÿ
6. ğŸ“ ä¿ç•™åŸæ–‡ - ä¸è¿›è¡Œä¸­è‹±æ–‡ç¿»è¯‘

ä½¿ç”¨æ–¹æ³•ï¼š
python docs_to_pdf_final.py                          # å®Œæ•´æµç¨‹ï¼ˆæ¨èï¼‰
python docs_to_pdf_final.py --sections 0,1 -w 8     # æŒ‡å®šç« èŠ‚å’Œè¿›ç¨‹æ•°
python docs_to_pdf_final.py --no-cache               # ç¦ç”¨ç¼“å­˜
python docs_to_pdf_final.py --skip-validation        # è·³è¿‡æ ¼å¼éªŒè¯
python docs_to_pdf_final.py --fix-files              # ä¿®å¤æ–‡ä»¶æ ¼å¼
"""

import os
import re
import yaml
import hashlib
import pickle
import argparse
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from concurrent.futures import ProcessPoolExecutor, as_completed

import mistune
from weasyprint import HTML, CSS
from weasyprint.text.fonts import FontConfiguration


# ============================================================================
# Recipe ç¼–å·æ˜ å°„
# ============================================================================

RECIPE_NUMBERS = {
    # Network
    "01-Recipes/Network/network_sniffing.md": "R01",
    "01-Recipes/Network/crypto_analysis.md": "R02",
    "01-Recipes/Network/tls_fingerprinting_guide.md": "R03",
    "01-Recipes/Network/ja3_fingerprinting.md": "R04",
    "01-Recipes/Network/ja4_fingerprinting.md": "R05",
    # Anti-Detection
    "01-Recipes/Anti-Detection/frida_anti_debugging.md": "R06",
    "01-Recipes/Anti-Detection/xposed_anti_debugging.md": "R07",
    "01-Recipes/Anti-Detection/captcha_bypassing_techniques.md": "R08",
    "01-Recipes/Anti-Detection/app_hardening_identification.md": "R09",
    "01-Recipes/Anti-Detection/device_fingerprinting_and_bypass.md": "R10",
    "01-Recipes/Anti-Detection/mobile_app_sec_and_anti_bot.md": "R11",
    # Unpacking
    "01-Recipes/Unpacking/un-packing.md": "R12",
    "01-Recipes/Unpacking/frida_unpacking_and_so_fixing.md": "R13",
    "01-Recipes/Unpacking/so_obfuscation_deobfuscation.md": "R14",
    "01-Recipes/Unpacking/so_string_deobfuscation.md": "R15",
    # Analysis
    "01-Recipes/Analysis/re_workflow.md": "R16",
    "01-Recipes/Analysis/static_analysis_deep_dive.md": "R17",
    "01-Recipes/Analysis/dynamic_analysis_deep_dive.md": "R18",
    "01-Recipes/Analysis/ollvm_deobfuscation.md": "R19",
    "01-Recipes/Analysis/vmp_analysis.md": "R20",
    "01-Recipes/Analysis/js_obfuscator.md": "R21",
    "01-Recipes/Analysis/js_vmp.md": "R22",
    "01-Recipes/Analysis/native_string_obfuscation.md": "R23",
    # Automation
    "01-Recipes/Automation/automation_and_device_farming.md": "R24",
    "01-Recipes/Automation/dial_up_proxy_pools.md": "R25",
    "01-Recipes/Automation/proxy_pool_design.md": "R26",
    "01-Recipes/Automation/scrapy.md": "R27",
    "01-Recipes/Automation/scrapy_redis_distributed.md": "R28",
    "01-Recipes/Automation/docker_deployment.md": "R29",
    "01-Recipes/Automation/virtualization_and_containers.md": "R30",
    "01-Recipes/Automation/web_anti_scraping.md": "R31",
    # Scripts
    "01-Recipes/Scripts/frida_script_examples.md": "R32",
    "01-Recipes/Scripts/frida_common_scripts.md": "R33",
    "01-Recipes/Scripts/automation_scripts.md": "R34",
    "01-Recipes/Scripts/native_hooking.md": "R35",
    "01-Recipes/Scripts/objection_snippets.md": "R36",
    "01-Recipes/Scripts/c_for_emulation.md": "R37",
}


def add_recipe_number_to_content(content: str, path: str) -> str:
    """ç»™ Recipe å†…å®¹çš„æ ‡é¢˜æ·»åŠ ç¼–å·å‰ç¼€"""
    if path in RECIPE_NUMBERS:
        recipe_num = RECIPE_NUMBERS[path]
        # åŒ¹é…ç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜ (# xxx)
        pattern = r'^(#\s+)(.+)$'
        def replace_title(match):
            return f"{match.group(1)}{recipe_num}: {match.group(2)}"
        # åªæ›¿æ¢ç¬¬ä¸€ä¸ªåŒ¹é…
        content = re.sub(pattern, replace_title, content, count=1, flags=re.MULTILINE)
    return content


# ============================================================================
# æ ¼å¼éªŒè¯å’Œä¿®å¤æ¨¡å—
# ============================================================================

class QuickFormatFixer:
    """å¿«é€Ÿæ ¼å¼ä¿®å¤å™¨"""

    @staticmethod
    def fix_file_issues(file_path: str) -> int:
        """ä¿®å¤æ–‡ä»¶ä¸­çš„å¸¸è§æ ¼å¼é—®é¢˜"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
        except:
            return 0

        original_lines = lines[:]
        fixes = 0

        # 1. ä¿®å¤æœªé—­åˆçš„ä»£ç å—
        in_code_block = False
        for line in lines:
            if re.match(r'^```', line):
                in_code_block = not in_code_block

        if in_code_block:
            if lines and not lines[-1].endswith('\n'):
                lines[-1] += '\n'
            lines.append('```\n')
            fixes += 1

        # 2. ä¿®å¤åˆ—è¡¨æ ‡è®°åç¼ºå°‘ç©ºæ ¼
        for i, line in enumerate(lines):
            match = re.match(r'^(\s*)([-*+]|\d+\.)([^\s])', line)
            if match:
                indent = match.group(1)
                marker = match.group(2)
                rest = line[len(indent) + len(marker):]
                lines[i] = f"{indent}{marker} {rest}"
                fixes += 1

        # 3. ä¿®å¤æ ‡é¢˜åç¼ºå°‘ç©ºæ ¼
        for i, line in enumerate(lines):
            match = re.match(r'^(#{1,6})([^\s])', line)
            if match:
                hashes = match.group(1)
                rest = line[len(hashes):]
                lines[i] = f"{hashes} {rest}"
                fixes += 1

        # å¦‚æœæœ‰ä¿®å¤ï¼Œå†™å›æ–‡ä»¶
        if fixes > 0 and lines != original_lines:
            try:
                # å¤‡ä»½åŸæ–‡ä»¶
                backup_path = f"{file_path}.backup"
                with open(backup_path, 'w', encoding='utf-8') as f:
                    f.writelines(original_lines)

                # å†™å…¥ä¿®å¤åçš„å†…å®¹
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.writelines(lines)
            except:
                return 0

        return fixes


# ============================================================================
# ä¸­æ–‡æ³¨é‡Šç¿»è¯‘æ¨¡å—
# ============================================================================

class ChineseCommentTranslator:
    """ç¿»è¯‘ä»£ç ä¸­çš„ä¸­æ–‡æ³¨é‡Šä¸ºè‹±æ–‡"""

    # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
    RE_CHINESE = re.compile(r'[\u4e00-\u9fa5]')
    RE_CODE_BLOCK = re.compile(r'```(\w*)\n(.*?)```', re.DOTALL)

    # ç¿»è¯‘è¯å…¸ï¼ˆç±»å˜é‡ï¼Œæ‰€æœ‰å®ä¾‹å…±äº«ï¼‰
    REPLACEMENTS = {
        'ç»•è¿‡': 'Bypass', 'åè°ƒè¯•': 'Anti-Debugging', 'æ£€æµ‹': 'Detection',
        'ç­–ç•¥': 'Strategy', 'ä¿®æ”¹': 'Modify', 'æ‹¦æˆª': 'Intercept',
        'è¿”å›': 'Return', 'è°ƒç”¨': 'Call', 'å‡½æ•°': 'Function',
        'æ–¹æ³•': 'Method', 'ç±»': 'Class', 'å¯¹è±¡': 'Object',
        'å‚æ•°': 'Parameter', 'å˜é‡': 'Variable', 'æ³¨é‡Š': 'Comment',
        'ä»£ç ': 'Code', 'è„šæœ¬': 'Script', 'é…ç½®': 'Config',
        'è®¾ç½®': 'Setting', 'åˆå§‹åŒ–': 'Initialize', 'å¤„ç†': 'Process',
        'è§£æ': 'Parse', 'ç”Ÿæˆ': 'Generate', 'åˆ›å»º': 'Create',
        'åˆ é™¤': 'Delete', 'æ›´æ–°': 'Update', 'è·å–': 'Get',
    }

    def __init__(self):
        self.cache = {}

    @classmethod
    def has_chinese(cls, text):
        """æ£€æµ‹æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡"""
        return bool(cls.RE_CHINESE.search(text))

    def translate_text(self, text):
        """ç¿»è¯‘å•è¡Œæ–‡æœ¬"""
        if not self.has_chinese(text):
            return text

        if text in self.cache:
            return self.cache[text]

        result = text
        for zh, en in self.REPLACEMENTS.items():
            result = result.replace(zh, en)

        self.cache[text] = result
        return result

    def translate_code_block(self, code):
        """ç¿»è¯‘ä»£ç å—ä¸­çš„ä¸­æ–‡æ³¨é‡Š"""
        lines = code.split('\n')
        translated = []

        comment_patterns = [
            re.compile(r'^(\s*//\s*)(.+)$'),  # JavaScript, Java, C++
            re.compile(r'^(\s*#\s*)(.+)$'),   # Python, Shell
            re.compile(r'(.+?)(//|#)(\s*)(.+)$'),  # è¡Œå†…æ³¨é‡Š
        ]

        for line in lines:
            for pattern in comment_patterns:
                match = pattern.match(line)
                if match:
                    groups = match.groups()
                    if len(groups) == 2 and self.has_chinese(groups[1]):
                        prefix = groups[0]
                        comment = groups[1]
                        line = prefix + self.translate_text(comment)
                        break
                    elif len(groups) == 4 and self.has_chinese(groups[3]):
                        code_part = groups[0]
                        marker = groups[1]
                        space = groups[2]
                        comment = groups[3]
                        line = code_part + marker + space + self.translate_text(comment)
                        break

            translated.append(line)

        return '\n'.join(translated)


# ============================================================================
# å¹¶è¡Œå¤„ç†æ¨¡å—
# ============================================================================

def process_single_markdown_file(args):
    """å¤„ç†å•ä¸ªmarkdownæ–‡ä»¶ï¼ˆç”¨äºå¹¶è¡Œæ‰§è¡Œï¼‰"""
    file_path, path, counter, use_cache, cache_dir, path_to_anchor = args

    try:
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{path}_{counter}"
        cache_file = os.path.join(cache_dir,
                                  f"{hashlib.md5(cache_key.encode()).hexdigest()}.pkl")

        file_hash = hashlib.md5(open(file_path, 'rb').read()).hexdigest()

        if use_cache and os.path.exists(cache_file):
            try:
                with open(cache_file, 'rb') as f:
                    cached_data = pickle.load(f)
                    if cached_data['hash'] == file_hash:
                        return cached_data['html'], counter, path
            except:
                pass

        # è¯»å–æ–‡ä»¶
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # ç»™ Recipe æ·»åŠ ç¼–å·å‰ç¼€
        content = add_recipe_number_to_content(content, path)

        # æ³¨é‡Šç¿»è¯‘åŠŸèƒ½ - ä¸è¿›è¡Œä¸­è‹±æ–‡ç¿»è¯‘
        # translator = ChineseCommentTranslator()
        #
        # def translate_code_block(match):
        #     language = match.group(1) or ''
        #     code = match.group(2)
        #     translated_code = translator.translate_code_block(code)
        #     return f'```{language}\n{translated_code}\n```'
        #
        # content = ChineseCommentTranslator.RE_CODE_BLOCK.sub(
        #     translate_code_block, content)

        # è½¬æ¢å†…éƒ¨é“¾æ¥ä¸ºPDFé”šç‚¹
        content = convert_internal_links_in_content(content, path_to_anchor)

        # è½¬æ¢ä¸ºHTML
        html_content = mistune.html(content)

        # ç¼“å­˜ç»“æœ
        if use_cache:
            os.makedirs(cache_dir, exist_ok=True)
            with open(cache_file, 'wb') as f:
                pickle.dump({
                    'hash': file_hash,
                    'html': html_content
                }, f)

        return html_content, counter, path

    except Exception as e:
        print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return None, counter, path


def convert_internal_links_in_content(content, path_to_anchor):
    """è½¬æ¢markdownå†…å®¹ä¸­çš„å†…éƒ¨é“¾æ¥ä¸ºPDFé”šç‚¹"""

    def replace_link(match):
        link_text = match.group(1)
        link_url = match.group(2)

        # åªå¤„ç†ç›¸å¯¹è·¯å¾„çš„ .md é“¾æ¥
        if not (link_url.endswith('.md') or '.md#' in link_url):
            return match.group(0)

        # æå–æ–‡ä»¶è·¯å¾„å’Œé”šç‚¹
        if '#' in link_url:
            file_path, anchor = link_url.split('#', 1)
        else:
            file_path = link_url
            anchor = None

        # è§„èŒƒåŒ–è·¯å¾„
        normalized_path = file_path
        while normalized_path.startswith('./'):
            normalized_path = normalized_path[2:]
        while normalized_path.startswith('../'):
            normalized_path = normalized_path[3:]

        # æŸ¥æ‰¾å¯¹åº”çš„é”šç‚¹ID
        target_anchor = None
        if normalized_path in path_to_anchor:
            target_anchor = path_to_anchor[normalized_path]
        else:
            # æ¨¡ç³ŠåŒ¹é…æ–‡ä»¶å
            filename = normalized_path.split('/')[-1]
            for path, anchor_id in path_to_anchor.items():
                if path.endswith(filename):
                    target_anchor = anchor_id
                    break

        if target_anchor:
            if anchor:
                return f'[{link_text}](#{target_anchor}-{anchor})'
            else:
                return f'[{link_text}](#{target_anchor})'
        else:
            # æ‰¾ä¸åˆ°æ˜ å°„ï¼Œè¿”å›çº¯æ–‡æœ¬
            return f'{link_text} ğŸ“„'

    # å¤„ç†æ‰€æœ‰é“¾æ¥
    content = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', replace_link, content)
    return content


# ============================================================================
# ä¸»è½¬æ¢å™¨
# ============================================================================

class FinalDocsToPDFConverter:
    """æœ€ç»ˆå®Œå–„ç‰ˆPDFè½¬æ¢å™¨"""

    def __init__(self, docs_dir="docs", mkdocs_file="mkdocs.yml",
                 section_filter=None, validate=True, auto_fix=False,
                 use_cache=True, workers=None):
        self.docs_dir = docs_dir
        self.mkdocs_file = mkdocs_file
        self.output_dir = "output"
        self.cache_dir = os.path.join(self.output_dir, ".cache")
        self.nav_structure = []
        self.font_config = FontConfiguration()
        self.path_to_anchor = {}
        self.section_filter = section_filter
        self.validate = validate
        self.auto_fix = auto_fix
        self.use_cache = use_cache
        self.workers = workers or os.cpu_count()

        # ä½œè€…ä¿¡æ¯
        self.author_email = "overkazaf@gmail.com"
        self.author_wechat = "_0xAF_"
        self.created_date = "2025-08-01"
        self.revision_date = "2025-12-20"

        os.makedirs(self.output_dir, exist_ok=True)
        if use_cache:
            os.makedirs(self.cache_dir, exist_ok=True)

    def load_navigation_structure(self):
        """ä»mkdocs.ymlåŠ è½½å¯¼èˆªç»“æ„"""
        try:
            with open(self.mkdocs_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                self.nav_structure = config.get('nav', [])
                print(f"âœ… å·²åŠ è½½å¯¼èˆªç»“æ„ï¼Œå…± {len(self.nav_structure)} ä¸ªä¸»è¦éƒ¨åˆ†")
                return self.nav_structure
        except Exception as e:
            print(f"âŒ åŠ è½½mkdocs.ymlå¤±è´¥: {e}")
            return []

    def should_include_section(self, section_idx, section_name):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åŒ…å«è¯¥ç« èŠ‚"""
        if self.section_filter is None:
            return True

        if section_idx in self.section_filter:
            return True

        for filter_name in self.section_filter:
            if isinstance(filter_name, str) and filter_name.lower() in section_name.lower():
                return True

        return False

    def build_path_anchor_mapping(self):
        """é¢„å…ˆæ„å»ºæ–‡ä»¶è·¯å¾„åˆ°é”šç‚¹IDçš„æ˜ å°„"""
        counter = 0

        def scan_nav_items(nav_items):
            nonlocal counter
            for item in nav_items:
                if isinstance(item, dict):
                    for title, path in item.items():
                        if isinstance(path, str):
                            counter += 1
                            anchor_id = f"section-{counter}"
                            self.path_to_anchor[path] = anchor_id
                        elif isinstance(path, list):
                            scan_nav_items(path)

        for section in self.nav_structure:
            if isinstance(section, dict):
                for section_name, items in section.items():
                    if section_name != "Home" and isinstance(items, list):
                        scan_nav_items(items)

        print(f"ğŸ“‹ å·²å»ºç«‹ {len(self.path_to_anchor)} ä¸ªæ–‡ä»¶è·¯å¾„æ˜ å°„")

    def validate_and_fix_files(self):
        """éªŒè¯å¹¶ä¿®å¤æ–‡ä»¶æ ¼å¼"""
        if not self.validate:
            return

        print("\nğŸ” éªŒè¯æ–‡ä»¶æ ¼å¼...")

        total_issues = 0
        total_fixes = 0

        for path, anchor_id in self.path_to_anchor.items():
            file_path = os.path.join(self.docs_dir, path)
            if not os.path.exists(file_path):
                continue

            # æ£€æŸ¥æ˜¯å¦æœ‰é—®é¢˜
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                has_issues = False

                # æ£€æŸ¥æœªé—­åˆçš„ä»£ç å—
                in_code_block = False
                for line in content.split('\n'):
                    if re.match(r'^```', line):
                        in_code_block = not in_code_block
                if in_code_block:
                    has_issues = True
                    total_issues += 1

                if has_issues and self.auto_fix:
                    fixes = QuickFormatFixer.fix_file_issues(file_path)
                    total_fixes += fixes

            except:
                continue

        if total_issues > 0:
            print(f"âš ï¸  å‘ç° {total_issues} ä¸ªæ ¼å¼é—®é¢˜")
            if self.auto_fix:
                print(f"âœ… å·²è‡ªåŠ¨ä¿®å¤ {total_fixes} ä¸ªé—®é¢˜")
        else:
            print("âœ… æ‰€æœ‰æ–‡ä»¶æ ¼å¼æ­£ç¡®")

    def collect_files_to_process(self):
        """æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶"""
        files_to_process = []
        article_counter = 0

        def collect_nav_items(nav_items):
            nonlocal article_counter
            for item in nav_items:
                if isinstance(item, dict):
                    for title, path in item.items():
                        if isinstance(path, str):
                            article_counter += 1
                            file_path = os.path.join(self.docs_dir, path)
                            if os.path.exists(file_path):
                                files_to_process.append((
                                    file_path, path, article_counter,
                                    self.use_cache, self.cache_dir,
                                    self.path_to_anchor
                                ))
                        elif isinstance(path, list):
                            collect_nav_items(path)

        section_idx = 0
        for section in self.nav_structure:
            if isinstance(section, dict):
                for section_name, items in section.items():
                    if section_name == "Home":
                        section_idx += 1
                        continue

                    if not self.should_include_section(section_idx, section_name):
                        section_idx += 1
                        continue

                    section_idx += 1
                    if isinstance(items, list):
                        collect_nav_items(items)

        return files_to_process

    def merge_docs_files_parallel(self):
        """å¹¶è¡Œåˆå¹¶æ‰€æœ‰docsæ–‡ä»¶"""
        if not self.nav_structure:
            self.load_navigation_structure()

        self.build_path_anchor_mapping()

        # éªŒè¯å’Œä¿®å¤ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self.validate:
            self.validate_and_fix_files()

        # åˆ›å»ºåŸºç¡€HTML
        full_html = """
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Android Reverse Engineering Cookbook</title>
        </head>
        <body>
        """

        # æ·»åŠ å°é¢å’Œç›®å½•
        full_html += self.create_cover_page()
        full_html += self.create_table_of_contents()

        # æ”¶é›†æ‰€æœ‰è¦å¤„ç†çš„æ–‡ä»¶
        files_to_process = self.collect_files_to_process()
        print(f"\nğŸš€ å¼€å§‹å¹¶è¡Œå¤„ç† {len(files_to_process)} ä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨ {self.workers} ä¸ªå·¥ä½œè¿›ç¨‹...")

        # å¹¶è¡Œå¤„ç†æ–‡ä»¶
        results = {}
        with ProcessPoolExecutor(max_workers=self.workers) as executor:
            futures = {executor.submit(process_single_markdown_file, args): args
                      for args in files_to_process}

            completed = 0
            for future in as_completed(futures):
                html_content, counter, path = future.result()
                if html_content:
                    results[counter] = (html_content, path)
                    completed += 1
                    if completed % 10 == 0 or completed == len(files_to_process):
                        print(f"  è¿›åº¦: {completed}/{len(files_to_process)}")

        print(f"âœ… å¹¶è¡Œå¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(results)} ä¸ªæ–‡ä»¶")

        # æŒ‰é¡ºåºæ·»åŠ åˆ°HTML
        section_icons = {
            "Home": "ğŸ ",
            "Quick-Start": "ğŸš€",
            "Recipes": "ğŸ“–",
            "Tools": "ğŸ› ï¸",
            "Case-Studies": "ğŸ’¼",
            "Reference": "ğŸ“š",
            "Appendix": "ğŸ“",
            "Foundations": "ğŸ“±",
            "Tooling": "ğŸ”§",
            "Techniques": "âš™ï¸",
            "Advanced-Topics": "ğŸ“",
            "Engineering": "ğŸ‘·",
            "Data-Analysis": "ğŸ“Š",
            "Scripts": "ğŸ“",
            "Others": "ğŸ“¦"
        }

        section_idx = 0
        for section in self.nav_structure:
            if isinstance(section, dict):
                for section_name, items in section.items():
                    if section_name == "Home":
                        section_idx += 1
                        continue

                    if not self.should_include_section(section_idx, section_name):
                        section_idx += 1
                        continue

                    icon = section_icons.get(section_name, "ğŸ“„")
                    section_idx += 1

                    full_html += f"""
                    <div class="chapter">
                        <h1 class="no-page-break">{icon} {section_name}</h1>
                    """

                    # æ”¶é›†è¯¥sectionä¸‹çš„æ‰€æœ‰ç»“æœ
                    def add_results(nav_items, html_output):
                        for item in nav_items:
                            if isinstance(item, dict):
                                for title, path in item.items():
                                    if isinstance(path, str) and path in self.path_to_anchor:
                                        counter = int(self.path_to_anchor[path].split('-')[1])
                                        if counter in results:
                                            html_content, _ = results[counter]
                                            anchor_id = self.path_to_anchor[path]
                                            html_output.append(f"""
                                            <div class="section" id="{anchor_id}">
                                                <h2>{counter}. {title}</h2>
                                                {html_content}
                                            </div>
                                            """)
                                    elif isinstance(path, list):
                                        add_results(path, html_output)

                    section_html = []
                    if isinstance(items, list):
                        add_results(items, section_html)
                    full_html += ''.join(section_html)
                    full_html += "</div>"

        full_html += """
        </body>
        </html>
        """

        return full_html

    def create_cover_page(self):
        """åˆ›å»ºå°é¢é¡µé¢"""
        return f"""
        <div class="cover-page">
            <div style="margin-top: 150pt;">
                <h1 style="font-size: 36pt; color: #1a1a1a; margin-bottom: 30pt; border: none; page-break-before: auto;" class="no-page-break">
                    Android Reverse Engineering Cookbook
                </h1>
                <h2 style="font-size: 20pt; color: #666; font-weight: 400; border: none; padding: 0;">
                    Complete Guide to Android Security Analysis
                </h2>
                <div style="margin-top: 80pt; font-size: 14pt; color: #888;">
                    <p>Foundations, Tools, Techniques, and Advanced Topics</p>
                    <p>Covers Frida, Unidbg, Xposed, IDA Pro and More</p>
                    <p>Including Data Analysis, Engineering and Case Studies</p>
                </div>
            </div>
        </div>
        <div style="page-break-before: always; text-align: center; margin-top: 80pt;">
            <div style="font-size: 12pt; color: #aaa;">
                <p style="font-size: 48pt; margin-bottom: 15pt;">ğŸ§‘â€ğŸ’»</p>
                <p style="font-size: 16pt; color: #666; margin-bottom: 20pt;"><strong>Authors: +5, Gemini Pro 3.0, Claude Code Opus 4.5</strong></p>
                <p>ğŸ“§ Email: {self.author_email}</p>
                <p>ğŸ’¬ WeChat: {self.author_wechat}</p>
                <p style="margin-top: 30pt;">ğŸ“… Created: {self.created_date}</p>
                <p>ğŸ”„ Last Revised: {self.revision_date}</p>
                <p>ğŸ“Œ Version: v2.0</p>
            </div>
            <div style="margin-top: 40pt; padding: 25pt 40pt; background-color: #fff8e1; border-radius: 8pt; border-left: 4px solid #ffa726;">
                <p style="font-size: 13pt; color: #e65100; font-weight: 600; margin-bottom: 15pt; text-align: center;">
                    ğŸ“– å…³äºè¿™æœ¬é£Ÿè°±çš„è¯ç”Ÿ | About This Cookbook
                </p>
                <p style="font-size: 10.5pt; color: #444; line-height: 1.9; text-align: justify; margin-bottom: 12pt;">
                    è¿™æœ¬é£Ÿè°±çš„è¯ç”Ÿï¼Œæ˜¯ä¸€æ¬¡æœ‰è¶£çš„<strong>äººæœºåä½œ</strong>å®éªŒã€‚é™¤äº†ç¬”è€…ï¼ˆ<strong>+5</strong>ï¼‰åœ¨Androidé€†å‘å·¥ç¨‹é¢†åŸŸçš„æ—¥å¸¸è®°å½•å’Œå®æˆ˜ç»éªŒç§¯ç´¯ï¼Œ
                    æœ¬ä¹¦è¿˜å¾—åˆ°äº†ä¸¤ä½AIåŠ©æ‰‹çš„é¼åŠ›æ”¯æŒâ€”â€”<strong>Gemini Pro 3.0</strong>å’Œ<strong>Claude Code Opus 4.5</strong>ã€‚
                    è¿™ä¸ªåä½œè¿‡ç¨‹å°±åƒä¸€ä¸ªçœŸå®çš„æŠ€æœ¯å›¢é˜Ÿï¼š
                </p>
                <div style="margin-left: 20pt; margin-bottom: 12pt;">
                    <p style="font-size: 10pt; color: #444; line-height: 1.7; margin-bottom: 8pt;">
                        ğŸ“š <strong>Gemini Pro 3.0</strong> åŒ–èº«"ç§‘ç ”è€å¸ˆå‚…"ï¼šè´Ÿè´£æµ·é‡æŠ€æœ¯çŸ¥è¯†ç‚¹çš„è°ƒç ”ã€æ¢³ç†ä¸å‘æ•£ï¼Œ
                        ä» arXiv å‰æ²¿è®ºæ–‡åˆ°å·¥ä¸šç•Œå®è·µèµ„æ–™çš„æ·±åº¦é˜…è¯»ä¸åˆ†æï¼Œä»¥åŠæä¾›æŠ€æœ¯æ€è·¯å’Œè§£å†³æ–¹æ¡ˆå»ºè®®ï¼Œ
                        å°±åƒå›¢é˜Ÿä¸­åšå­¦å¤šæ‰çš„æŠ€æœ¯é¡¾é—®å’ŒçŸ¥è¯†ç®¡å®¶ã€‚
                    </p>
                    <p style="font-size: 10pt; color: #444; line-height: 1.7; margin-bottom: 8pt;">
                        ğŸ’» <strong>Claude Code Opus 4.5</strong> åŒ–èº«"ç‰›é©¬ç¨‹åºå‘˜"ï¼šè´Ÿè´£æ‰€æœ‰ä»£ç ç¤ºä¾‹çš„ç¼–å†™ä¸è°ƒè¯•ã€
                        å¤§å‹ä»£ç åº“çš„æ·±åº¦ç†è§£ä¸é‡æ„ã€æ¶æ„æµç¨‹å›¾çš„åˆ›å»ºã€æ‰¹é‡å¤„ç† Markdown æ ¼å¼é—®é¢˜ã€è‡ªåŠ¨åŒ–æ–‡æ¡£ç”Ÿæˆæµç¨‹ï¼Œ
                        ä»¥åŠä»£ç è´¨é‡æŠŠå…³ï¼Œå°±åƒå›¢é˜Ÿä¸­ 7x24 åœ¨çº¿çš„å…¨æ ˆå¼€å‘å’Œ DevOps å·¥ç¨‹å¸ˆã€‚
                    </p>
                    <p style="font-size: 10pt; color: #444; line-height: 1.7; margin-bottom: 8pt;">
                        ğŸ¯ <strong>+5</strong>ï¼ˆæŠ€æœ¯è´Ÿè´£äºº & æ€»ç¼–è¾‘ï¼‰ï¼šè´Ÿè´£æ•´ä½“æ¶æ„è®¾è®¡ã€æŠ€æœ¯æ–¹å‘æŠŠæ§ã€å†…å®¹å®¡æ ¸ä¿®è®¢ã€
                        ä»¥åŠæœ€ç»ˆè´¨é‡ä¿éšœï¼Œå°±åƒå›¢é˜Ÿä¸­çš„Tech Leadå’ŒEditor-in-Chiefã€‚
                    </p>
                </div>
                <p style="font-size: 10pt; color: #666; line-height: 1.8; text-align: justify; font-style: italic; margin-bottom: 12pt;">
                    This cookbook is born from an intriguing <strong>human-AI collaboration</strong>, like a real tech team:
                    <strong>Gemini Pro 3.0</strong> (Research Guru) dives into arXiv papers, technical documentation, and industry practices;
                    <strong>Claude Code Opus 4.5</strong> (Workhorse Coder) handles all code examples, codebase comprehension,
                    architecture diagrams, Markdown formatting, and documentation automation around the clock;
                    <strong>+5</strong> (Tech Lead & Editor-in-Chief) steers the architecture, technical direction,
                    content revision, and final quality assurance.
                </p>
                <p style="font-size: 10pt; color: #555; line-height: 1.8; text-align: justify; margin-bottom: 12pt;">
                    ğŸ¤ æˆ‘ç›¸ä¿¡ï¼Œäººç±»çš„å®è·µæ™ºæ…§ä¸AIçš„çŸ¥è¯†æ•´åˆèƒ½åŠ›ç›¸ç»“åˆï¼Œèƒ½å¤Ÿåˆ›é€ å‡ºæ›´ä¼˜è´¨çš„å­¦ä¹ èµ„æºã€‚
                    å¸Œæœ›è¿™ç§è·¨è¶Šäººæœºè¾¹ç•Œçš„åä½œæ–¹å¼ï¼Œèƒ½ä¸ºå¤§å®¶å¸¦æ¥<strong>ä¸ä¸€æ ·çš„é˜…è¯»ä½“éªŒ</strong>ï¼Œ
                    ä¹Ÿä¸ºæŠ€æœ¯æ–‡æ¡£çš„åˆ›ä½œå¼€è¾Ÿæ–°çš„å¯èƒ½æ€§ã€‚
                </p>
                <p style="font-size: 10pt; color: #444; line-height: 1.8; text-align: justify; border-top: 1px dashed #ffa726; padding-top: 12pt;">
                    âœˆï¸ <strong>åˆ›ä½œåˆè¡·</strong>ï¼šè¿™æœ¬é£Ÿè°±æœ€åˆæ˜¯ä¸ºäº†è®°å½•ç¬”è€…æ—¥å¸¸çš„é€†å‘å·¥ä½œå’ŒæŠ€æœ¯ç§¯ç´¯ã€‚
                    åœ¨æ¼«é•¿çš„é£æœºæ—…é€”ä¸­ï¼Œæˆ–æ˜¯åœ¨å’–å•¡é¦†å°æ†©æ—¶ï¼Œç¿»é˜…è¿™äº›ç²¾å¿ƒæ•´ç†çš„æŠ€æœ¯ç¬”è®°ï¼Œ
                    å›é¡¾é‚£äº›æœ‰æ„æ€çš„é€†å‘çŸ¥è¯†ç‚¹å’Œè§£é¢˜æ€è·¯ï¼Œæ—¢æ˜¯ä¸€ç§æ”¾æ¾ï¼Œä¹Ÿæ˜¯ä¸€ç§å­¦ä¹ ã€‚
                    å¸Œæœ›è¿™æœ¬ä¹¦ä¹Ÿèƒ½æˆä¸ºä½ æ—…é€”ä¸­çš„è‰¯ä¼´ï¼Œè®©æŠ€æœ¯å­¦ä¹ å˜å¾—æ›´åŠ è½»æ¾æ„‰å¿«ã€‚
                </p>
            </div>
            <div style="margin-top: 30pt; padding: 25pt 40pt; border-top: 1px solid #ddd; border-bottom: 1px solid #ddd;">
                <p style="font-size: 11pt; color: #555; font-style: italic; line-height: 1.8; text-align: center;">
                    "If the highest aim of a captain were to preserve his ship,<br/>
                    he would keep it in port forever."
                </p>
                <p style="font-size: 9pt; color: #888; text-align: right; margin-top: 10pt;">
                    â€” St. Thomas Aquinas, <em>Summa Theologica</em> (1265-1274)
                </p>
            </div>
            <div style="margin-top: 30pt; padding: 25pt 40pt; background-color: #f9f9f9; border-radius: 8pt;">
                <p style="font-size: 10.5pt; color: #444; line-height: 1.9; text-align: justify; margin-bottom: 15pt;">
                    The journey begins with the thrill of solving puzzlesâ€”that exhilarating rush when code
                    finally yields its secrets. Yet seasoned reverse engineers walk a different path. They
                    remain humble, ever-curious, and deeply reflective. In time, they all return to first
                    principles: understanding how systems are <em>built</em> is the only true way to understand
                    how they can be <em>unraveled</em>.
                </p>
                <p style="font-size: 10pt; color: #666; line-height: 1.8; text-align: justify; font-style: italic;">
                    åˆæ¶‰æ­¤é“ï¼Œå¤šä¸ºç ´è§£ä¹‹æ—¶çš„å¿«æ„ã€‚è€Œè¡Œè‡³æ·±å¤„è€…ï¼Œæ—©å·²è¶…è¶Šè¿™ä»½æ¬£å–œã€‚ä»–ä»¬æ€€è°¦å‘ä¹‹å¿ƒï¼Œ
                    æŒæ±‚çŸ¥ä¹‹å¿µï¼Œå–„äºæ€è€ƒï¼Œæœ€ç»ˆéƒ½ä¼šå›å½’æŠ€æœ¯çš„æœ¬è´¨â€”â€”å”¯æœ‰æ´æ‚‰ç³»ç»Ÿ<strong>æ„å»º</strong>ä¹‹é“ï¼Œ
                    æ–¹èƒ½å‚é€å…¶<strong>æ‹†è§£</strong>ä¹‹æ³•ã€‚çŸ¥å·±çŸ¥å½¼ï¼Œç™¾æˆ˜ä¸æ®†ã€‚
                </p>
            </div>
        </div>
        """

    def create_table_of_contents(self):
        """åˆ›å»ºç®€åŒ–ç›®å½•é¡µé¢"""
        return """
        <div class="toc-page">
            <h1 class="toc-title no-page-break">ğŸ“š ç›®å½•</h1>
            <p style="text-align: center; color: #666; font-size: 12pt; margin-top: 20pt;">
                æœ¬ä¹¦æ¶µç›–Androidé€†å‘å·¥ç¨‹çš„å®Œæ•´çŸ¥è¯†ä½“ç³»<br/>
                åŒ…æ‹¬åŸºç¡€ç†è®ºã€å·¥å…·ä½¿ç”¨ã€å®æˆ˜æŠ€å·§å’Œé«˜çº§ä¸»é¢˜
            </p>
        </div>
        """

    def create_css_styles(self):
        """åˆ›å»ºPDFæ ·å¼ - å®Œå–„çš„ä¸­æ–‡å­—ä½“æ”¯æŒ"""
        css_content = """
        /* ä½¿ç”¨ç³»ç»Ÿå­—ä½“ç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤º */
        @font-face {
            font-family: 'Chinese Sans';
            src: url('file:///System/Library/Fonts/Hiragino Sans GB.ttc') format('truetype'),
                 url('file:///System/Library/Fonts/STHeiti Light.ttc') format('truetype'),
                 url('file:///System/Library/Fonts/Supplemental/Songti.ttc') format('truetype'),
                 url('file:///Library/Fonts/Arial Unicode.ttf') format('truetype');
            font-weight: normal;
        }

        @font-face {
            font-family: 'Chinese Sans';
            src: url('file:///System/Library/Fonts/Hiragino Sans GB.ttc') format('truetype'),
                 url('file:///System/Library/Fonts/STHeiti Medium.ttc') format('truetype'),
                 url('file:///System/Library/Fonts/Supplemental/Songti.ttc') format('truetype');
            font-weight: bold;
        }

        @font-face {
            font-family: 'Code Font';
            src: url('file:///System/Library/Fonts/Menlo.ttc') format('truetype'),
                 url('file:///System/Library/Fonts/Monaco.dfont') format('truetype'),
                 url('file:///Library/Fonts/Arial Unicode.ttf') format('truetype');
        }

        /* é¡µé¢è®¾ç½® */
        @page {
            size: A4;
            margin: 2.5cm 2cm 3cm 2cm;

            @top-left {
                content: "Android Reverse Engineering Cookbook";
                font-family: 'Chinese Sans', sans-serif;
                font-size: 10pt;
                color: #666;
                border-bottom: 1px solid #e0e0e0;
                padding-bottom: 5pt;
            }

            @top-right {
                content: "Page " counter(page);
                font-family: 'Chinese Sans', sans-serif;
                font-size: 10pt;
                color: #666;
                border-bottom: 1px solid #e0e0e0;
                padding-bottom: 5pt;
            }

            @bottom-center {
                content: "Â© 2025 Android Reverse Engineering Cookbook";
                font-family: 'Chinese Sans', sans-serif;
                font-size: 9pt;
                color: #999;
                border-top: 1px solid #e0e0e0;
                padding-top: 5pt;
            }
        }

        /* åŸºç¡€æ ·å¼ */
        body {
            font-family: 'Chinese Sans', 'Noto Sans SC', 'Microsoft YaHei', sans-serif;
            font-size: 11pt;
            line-height: 1.8;
            color: #333;
            background: white;
        }

        /* æ ‡é¢˜æ ·å¼ */
        h1 {
            font-family: 'Chinese Sans', sans-serif;
            font-size: 24pt;
            font-weight: 700;
            color: #1a1a1a;
            margin-top: 30pt;
            margin-bottom: 20pt;
            page-break-before: always;
            border-bottom: 3px solid #4a90e2;
            padding-bottom: 10pt;
        }

        h1.no-page-break {
            page-break-before: auto;
        }

        h2 {
            font-family: 'Chinese Sans', sans-serif;
            font-size: 18pt;
            font-weight: 600;
            color: #2c3e50;
            margin-top: 25pt;
            margin-bottom: 15pt;
            border-left: 4px solid #4a90e2;
            padding-left: 15pt;
            page-break-after: avoid;
        }

        h3 {
            font-family: 'Chinese Sans', sans-serif;
            font-size: 14pt;
            font-weight: 500;
            color: #34495e;
            margin-top: 20pt;
            margin-bottom: 12pt;
            page-break-after: avoid;
        }

        h4 {
            font-family: 'Chinese Sans', sans-serif;
            font-size: 12pt;
            font-weight: 500;
            color: #555;
            margin-top: 15pt;
            margin-bottom: 10pt;
            page-break-after: avoid;
        }

        /* æ®µè½æ ·å¼ */
        p {
            margin-bottom: 12pt;
            text-align: justify;
            orphans: 3;
            widows: 3;
        }

        /* åˆ—è¡¨æ ·å¼ */
        ul, ol {
            margin-bottom: 12pt;
            padding-left: 25pt;
        }

        li {
            margin-bottom: 6pt;
            orphans: 2;
            widows: 2;
        }

        /* ä»£ç æ ·å¼ */
        code {
            font-family: 'Code Font', 'Menlo', 'Monaco', 'Consolas', monospace;
            font-size: 9pt;
            background-color: #f8f9fa;
            padding: 2pt 4pt;
            border-radius: 3pt;
            border: 1px solid #e9ecef;
            word-wrap: break-word;
        }

        pre {
            font-family: 'Code Font', 'Menlo', 'Monaco', 'Consolas', monospace;
            font-size: 8.5pt;
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 6pt;
            padding: 12pt;
            margin: 12pt 0;
            overflow-x: auto;
            line-height: 1.5;
            white-space: pre-wrap;
            word-wrap: break-word;
            page-break-inside: avoid;
        }

        pre code {
            background: none;
            border: none;
            padding: 0;
            font-size: 8.5pt;
        }

        /* è¡¨æ ¼æ ·å¼ */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 15pt 0;
            font-size: 10pt;
            page-break-inside: avoid;
        }

        th, td {
            border: 1px solid #ddd;
            padding: 8pt 12pt;
            text-align: left;
            word-wrap: break-word;
        }

        th {
            background-color: #f8f9fa;
            font-weight: 600;
            color: #495057;
        }

        tr:nth-child(even) {
            background-color: #f8f9fa;
        }

        /* å¼•ç”¨æ ·å¼ */
        blockquote {
            border-left: 4px solid #6c757d;
            padding-left: 15pt;
            margin: 15pt 0;
            color: #6c757d;
            font-style: italic;
        }

        /* é“¾æ¥æ ·å¼ */
        a {
            color: #4a90e2;
            text-decoration: none;
            word-wrap: break-word;
        }

        /* å¼ºè°ƒæ ·å¼ */
        strong, b {
            font-weight: 600;
            color: #2c3e50;
        }

        em, i {
            font-style: italic;
            color: #555;
        }

        /* åˆ†éš”çº¿ */
        hr {
            border: none;
            border-top: 2px solid #e9ecef;
            margin: 25pt 0;
        }

        /* å°é¢æ ·å¼ */
        .cover-page {
            text-align: center;
            page-break-after: always;
        }

        /* ç›®å½•æ ·å¼ */
        .toc-page {
            page-break-after: always;
        }

        .toc-title {
            font-size: 28pt;
            font-weight: 700;
            text-align: center;
            color: #1a1a1a;
            margin-bottom: 40pt;
            border-bottom: 3px solid #4a90e2;
            padding-bottom: 15pt;
        }

        /* ç« èŠ‚æ ·å¼ */
        .chapter {
            page-break-before: always;
        }

        /* æ¯ä¸ªåºå·ç« èŠ‚å¦èµ·ä¸€é¡µ */
        .section {
            margin-bottom: 30pt;
            page-break-before: always;
        }

        /* ç¬¬ä¸€ä¸ªsectionä¸åˆ†é¡µï¼ˆç´§è·Ÿå¤§ç« èŠ‚æ ‡é¢˜ï¼‰ */
        .chapter .section:first-of-type {
            page-break-before: auto;
        }

        /* æ‰“å°ä¼˜åŒ– */
        @media print {
            body {
                -webkit-print-color-adjust: exact;
                print-color-adjust: exact;
            }
        }
        """

        return CSS(string=css_content, font_config=self.font_config)

    def generate_pdf(self, output_filename="android_reverse_engineering_cookbook_final.pdf"):
        """ç”ŸæˆPDFæ–‡ä»¶"""
        print("\nğŸš€ å¼€å§‹ç”ŸæˆPDF (Final Edition - å®Œå–„ç‰ˆ)...")
        print("=" * 60)
        print(f"âš¡ å¹¶è¡Œå¤„ç†: {self.workers} ä¸ªå·¥ä½œè¿›ç¨‹")
        print(f"ğŸ’¾ ç¼“å­˜: {'å¯ç”¨' if self.use_cache else 'ç¦ç”¨'}")
        print(f"ğŸ” éªŒè¯: {'å¯ç”¨' if self.validate else 'ç¦ç”¨'}")
        print(f"ğŸ”§ è‡ªåŠ¨ä¿®å¤: {'å¯ç”¨' if self.auto_fix else 'ç¦ç”¨'}")
        print("=" * 60)

        # åˆå¹¶æ‰€æœ‰docsæ–‡ä»¶
        html_content = self.merge_docs_files_parallel()

        # åˆ›å»ºCSSæ ·å¼
        css_styles = self.create_css_styles()

        # ç”ŸæˆPDF
        if os.path.dirname(output_filename):
            output_path = output_filename
        else:
            output_path = os.path.join(self.output_dir, output_filename)

        try:
            print("\nğŸ“„ æ­£åœ¨æ¸²æŸ“PDF...")
            html_doc = HTML(string=html_content)
            html_doc.write_pdf(
                output_path,
                stylesheets=[css_styles],
                font_config=self.font_config
            )

            file_size_mb = os.path.getsize(output_path) / 1024 / 1024

            print(f"\nâœ… PDFç”ŸæˆæˆåŠŸ!")
            print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {output_path}")
            print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")

            # ä¿å­˜HTMLç”¨äºè°ƒè¯•
            html_path = os.path.join(self.output_dir, "docs_final_debug.html")
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            print(f"ğŸ” è°ƒè¯•HTML: {html_path}")

            print("\n" + "=" * 60)
            print("ğŸ‰ PDFç”Ÿæˆå®Œæˆ!")
            print("âœ¨ ç‰¹æ€§:")
            print("   âœ… å¹¶è¡Œå¤„ç† - å¿«é€Ÿç”Ÿæˆ")
            print("   âœ… å®Œå–„ä¸­æ–‡æ”¯æŒ - æ— ç¼–ç é”™ä¹±")
            print("   âœ… PDFå†…é“¾æ¥è·³è½¬ - å®Œç¾å¯¼èˆª")
            print("   âœ… æ ¼å¼è‡ªåŠ¨ä¿®å¤ - ç¡®ä¿è´¨é‡")
            print("   âœ… æ™ºèƒ½ç¼“å­˜ - æé€ŸäºŒæ¬¡ç”Ÿæˆ")
            print("=" * 60)

            return output_path

        except Exception as e:
            print(f"\nâŒ PDFç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None


def parse_section_filter(sections_arg):
    """è§£æç« èŠ‚è¿‡æ»¤å‚æ•°"""
    if not sections_arg:
        return None

    result = []
    for item in sections_arg.split(','):
        item = item.strip()
        try:
            result.append(int(item))
        except ValueError:
            result.append(item)

    return result


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='Android Reverse Engineering Cookbook - Final PDF Generator',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s                                  # å®Œæ•´æµç¨‹ï¼ˆæ¨èï¼‰
  %(prog)s --sections 0,1 -w 8              # æŒ‡å®šç« èŠ‚å’Œè¿›ç¨‹æ•°
  %(prog)s --no-cache                       # ç¦ç”¨ç¼“å­˜ï¼ˆæ–‡ä»¶ä¿®æ”¹åï¼‰
  %(prog)s --skip-validation                # è·³è¿‡éªŒè¯å¿«é€Ÿç”Ÿæˆ
  %(prog)s --fix-files                      # ä¿®å¤æ–‡ä»¶æ ¼å¼é—®é¢˜
  %(prog)s --fix-files --no-cache -w 12     # ç»„åˆä½¿ç”¨
        """
    )
    parser.add_argument('--sections', '-s', type=str,
                       help='æŒ‡å®šè¦ç”Ÿæˆçš„ç« èŠ‚ï¼ˆç´¢å¼•æˆ–åç§°ï¼Œé€—å·åˆ†éš”ï¼‰')
    parser.add_argument('--output', '-o', type=str,
                       help='è¾“å‡ºæ–‡ä»¶å')
    parser.add_argument('--no-cache', action='store_true',
                       help='ç¦ç”¨ç¼“å­˜')
    parser.add_argument('--skip-validation', action='store_true',
                       help='è·³è¿‡æ ¼å¼éªŒè¯')
    parser.add_argument('--fix-files', action='store_true',
                       help='è‡ªåŠ¨ä¿®å¤æ–‡ä»¶æ ¼å¼é—®é¢˜')
    parser.add_argument('--workers', '-w', type=int,
                       help='å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤ï¼šCPUæ ¸å¿ƒæ•°ï¼‰')

    args = parser.parse_args()

    print("ğŸš€ Android Reverse Engineering Cookbook")
    print("   Final PDF Generator - å®Œå–„ç‰ˆ")
    print("=" * 60)
    print("âœ¨ é›†æˆæ‰€æœ‰ä¼˜ç‚¹:")
    print("   âš¡ å¹¶è¡Œå¤„ç† (2-4å€æé€Ÿ)")
    print("   ğŸ”¤ å®Œå–„ä¸­æ–‡æ”¯æŒ")
    print("   ğŸ”— PDFå†…é“¾æ¥è·³è½¬")
    print("   ğŸ”§ æ ¼å¼è‡ªåŠ¨ä¿®å¤")
    print("   ğŸ’¾ æ™ºèƒ½ç¼“å­˜ (10-20å€äºŒæ¬¡æé€Ÿ)")
    print("=" * 60)

    # æ£€æŸ¥ä¾èµ–
    try:
        import mistune
        import weasyprint
        import yaml
        print("âœ… ä¾èµ–æ£€æŸ¥é€šè¿‡")
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        print("è¯·è¿è¡Œ: pip install mistune weasyprint pillow pyyaml")
        return

    section_filter = parse_section_filter(args.sections) if args.sections else None

    converter = FinalDocsToPDFConverter(
        section_filter=section_filter,
        validate=not args.skip_validation,
        auto_fix=args.fix_files,
        use_cache=not args.no_cache,
        workers=args.workers
    )

    nav = converter.load_navigation_structure()
    if not nav:
        print("âŒ æœªæ‰¾åˆ°å¯¼èˆªç»“æ„")
        return

    if section_filter:
        print(f"\nğŸ“‹ å°†ç”Ÿæˆç« èŠ‚: {section_filter}")

    output_filename = args.output if args.output else "android_reverse_engineering_cookbook_final.pdf"
    if section_filter:
        base_name = output_filename.replace('.pdf', '')
        output_filename = f"{base_name}_partial.pdf"

    converter.generate_pdf(output_filename)


if __name__ == "__main__":
    main()
